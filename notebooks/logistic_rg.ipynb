{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de0e10",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.13.6)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Asus/Desktop/ml-models-from-scratch/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199584c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Logistic Regression from scratch\n",
    "rice_dataset_raw = pd.read_csv(\n",
    "    \"https://download.mlcc.google.com/mledu-datasets/Rice_Cammeo_Osmancik.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_dataset_raw.shape\n",
    "rice_dataset_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# Maximising log loss\n",
    "X = rice_dataset_raw.iloc[:, [0,1,2,3,4,5,6]].to_numpy()\n",
    "\n",
    "\n",
    "rice_dataset_raw[\"Class\"] = rice_dataset_raw[\"Class\"].map({\"Cammeo\": 1, \"Osmancik\": 0})\n",
    "\n",
    "Y = rice_dataset_raw.iloc[:, [7]].to_numpy()\n",
    "rice_dataset_raw[\"Class\"].unique()\n",
    "rice_dataset_raw.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Area\", \"Perimeter\", \"MajorAxisLength\", \"MinorAxisLength\", \"Eccentricity\", \"ConvexArea\", \"Extent\"]\n",
    "\n",
    "for i in range(len(X[0])):\n",
    "    plt.figure()\n",
    "    plt.hist(X[:, i][Y[:, 0] == 1], alpha=0.5, label=\"Cammeo\")\n",
    "    plt.hist(X[:, i][Y[:, 0] == 0], alpha=0.5, label=\"Osmancik\")\n",
    "    plt.title(features[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e41a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create five 2D plots of the features against each other, color-coded by class.\n",
    "for x_axis_data, y_axis_data in [\n",
    "    (\"Area\", \"Eccentricity\"),\n",
    "    (\"Convex_Area\", \"Perimeter\"),\n",
    "    (\"Major_Axis_Length\", \"Minor_Axis_Length\"),\n",
    "    (\"Perimeter\", \"Extent\"),\n",
    "    (\"Eccentricity\", \"Major_Axis_Length\"),\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.xlabel(x_axis_data)\n",
    "    plt.ylabel(y_axis_data)\n",
    "    plt.scatter(\n",
    "        rice_dataset_raw[x_axis_data][rice_dataset_raw[\"Class\"] == 1],\n",
    "        rice_dataset_raw[y_axis_data][rice_dataset_raw[\"Class\"] == 1],\n",
    "        label=\"Cammeo\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        rice_dataset_raw[x_axis_data][rice_dataset_raw[\"Class\"] == 0],\n",
    "        rice_dataset_raw[y_axis_data][rice_dataset_raw[\"Class\"] == 0],\n",
    "        label=\"Osmancik\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D plot bw diff metrics to pick best 3 features\n",
    "# Eccentricity, Area, MajorAxisLength\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(\n",
    "    rice_dataset_raw[\"Eccentricity\"][rice_dataset_raw[\"Class\"] == 1\n",
    "    ],\n",
    "    rice_dataset_raw[\"Area\"][rice_dataset_raw[\"Class\"] == 1],\n",
    "    rice_dataset_raw[\"Major_Axis_Length\"][rice_dataset_raw[\"Class\"] == 1],                \n",
    ")\n",
    "ax.scatter(\n",
    "    rice_dataset_raw[\"Eccentricity\"][rice_dataset_raw[\"Class\"] == 0\n",
    "    ],\n",
    "    rice_dataset_raw[\"Area\"][rice_dataset_raw[\"Class\"] == 0],\n",
    "    rice_dataset_raw[\"Major_Axis_Length\"][rice_dataset_raw[\"Class\"] == 0],                \n",
    ")\n",
    "ax.set_xlabel('Eccentricity')\n",
    "ax.set_ylabel('Area')\n",
    "ax.set_zlabel('Major Axis Length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising these 3 features using z score without sklearn\n",
    "X = rice_dataset_raw.iloc[:, [0, 2, 4]].to_numpy()\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "Y = rice_dataset_raw.iloc[:, [7]].to_numpy()\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data and split into training , validation, and test sets\n",
    "np.random.seed(42)\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "X_shuffled = X[shuffled_indices]\n",
    "Y_shuffled = Y[shuffled_indices]\n",
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))\n",
    "X_train, Y_train = X_shuffled[:train_size], Y_shuffled[:train_size]\n",
    "X_val, Y_val = X_shuffled[train_size:train_size + val_size], Y_shuffled[train_size:train_size + val_size]\n",
    "X_test, Y_test = X_shuffled[train_size + val_size:], Y_shuffled[train_size + val_size:]\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\n",
    "    \"Eccentricity\",\n",
    "    \"Major_Axis_Length\",\n",
    "    \"Area\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e497834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "# Prediction\n",
    "def predict(X, w, b):\n",
    "    z = np.dot(X, w) + b\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, lr=0.05, epochs=2000):\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros((n_features, 1))\n",
    "    b = 0\n",
    "\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = sigmoid(np.dot(X, w) + b)\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            loss = -(1 / n_samples) * np.sum(\n",
    "                y * np.log(y_pred + 1e-8) + (1 - y) * np.log(1 - y_pred + 1e-8)\n",
    "            )\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = train(X_train, Y_train, lr=0.05, epochs=2000)\n",
    "print(\"Weights:\", w.flatten())\n",
    "print(\"Bias:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation using validationo data \n",
    "# Accuracy, Precision, Recall, F1 Score calculation\n",
    "# Setting a variable threshold\n",
    "threshold = 0.35\n",
    "Y_val_pred_prob = predict(X_val, w, b)\n",
    "Y_val_pred = (Y_val_pred_prob >= threshold).astype(int)\n",
    "TP = np.sum((Y_val == 1) & (Y_val_pred == 1))\n",
    "TN = np.sum((Y_val == 0) & (Y_val_pred == 0\n",
    "))\n",
    "FP = np.sum((Y_val == 0) & (Y_val_pred == 1 ))\n",
    "FN = np.sum((Y_val == 1) & (Y_val_pred == 0))\n",
    "accuracy = (TP + TN) / len(Y_val)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1 Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "Y_test_pred_prob = predict(X_test, w, b)\n",
    "Y_test_pred = (Y_test_pred_prob >= threshold).astype(int)\n",
    "TP = np.sum((Y_test == 1) & (Y_test_pred == 1))\n",
    "TN = np.sum((Y_test == 0) & (Y_test_pred == 0))\n",
    "FP = np.sum((Y_test == 0) & (Y_test_pred == 1 ))\n",
    "FN = np.sum((Y_test == 1) & (Y_test_pred == 0))\n",
    "accuracy = (TP + TN) / len(Y_test)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating ROC and AUC without sklearn\n",
    "\n",
    "def compute_roc_auc(y_true, y_scores):\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "\n",
    "    P = np.sum(y_true == 1)\n",
    "    N = np.sum(y_true == 0)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "        TPR = TP / P if P > 0 else 0\n",
    "        FPR = FP / N if N > 0 else 0\n",
    "\n",
    "        tpr_list.append(TPR)\n",
    "        fpr_list.append(FPR)\n",
    "\n",
    "    tpr_array = np.array(tpr_list)\n",
    "    fpr_array = np.array(fpr_list)\n",
    "    # Ensure FPR is increasing\n",
    "    sorted_indices = np.argsort(fpr_array)\n",
    "    fpr_array = fpr_array[sorted_indices]\n",
    "    tpr_array = tpr_array[sorted_indices]\n",
    "\n",
    "    auc = np.trapezoid(tpr_array, fpr_array)\n",
    "\n",
    "    return fpr_array, tpr_array, auc\n",
    "fpr, tpr, auc = compute_roc_auc(Y_test, Y_test_pred_prob)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Plotting ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {auc\n",
    ":.4f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df63a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a decision boundary\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
